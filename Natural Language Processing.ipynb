{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-24T05:46:13.396130Z",
     "start_time": "2017-10-24T05:46:11.955690Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Count 189\n",
      "\n",
      "For Fold 0 as dev \n",
      "POS: 85, NEG: 85\n",
      "Correct: 17, Total: 19, Accuracy: 89.473684\n",
      "         ID Class Pred_Class\n",
      "8   ID-0869   NEG        POS\n",
      "11  ID-0885   NEG        POS\n",
      "\n",
      "For Fold 1 as dev \n",
      "POS: 87, NEG: 83\n",
      "Correct: 18, Total: 19, Accuracy: 94.736842\n",
      "         ID Class Pred_Class\n",
      "37  ID-0961   NEG        POS\n",
      "\n",
      "For Fold 2 as dev \n",
      "POS: 86, NEG: 84\n",
      "Correct: 18, Total: 19, Accuracy: 94.736842\n",
      "         ID Class Pred_Class\n",
      "51  ID-0993   NEG        POS\n",
      "\n",
      "For Fold 3 as dev \n",
      "POS: 84, NEG: 86\n",
      "Correct: 18, Total: 19, Accuracy: 94.736842\n",
      "         ID Class Pred_Class\n",
      "71  ID-1196   POS        NEG\n",
      "\n",
      "For Fold 4 as dev \n",
      "POS: 84, NEG: 86\n",
      "Correct: 17, Total: 19, Accuracy: 89.473684\n",
      "         ID Class Pred_Class\n",
      "76  ID-0997   NEG        POS\n",
      "77  ID-0971   NEG        POS\n",
      "\n",
      "For Fold 5 as dev \n",
      "POS: 87, NEG: 83\n",
      "Correct: 17, Total: 19, Accuracy: 89.473684\n",
      "          ID Class Pred_Class\n",
      "104  ID-0827   NEG        POS\n",
      "111  ID-0941   NEG        POS\n",
      "\n",
      "For Fold 6 as dev \n",
      "POS: 83, NEG: 87\n",
      "Correct: 15, Total: 19, Accuracy: 78.947368\n",
      "          ID Class Pred_Class\n",
      "118  ID-0905   NEG        POS\n",
      "123  ID-0963   NEG        POS\n",
      "127  ID-0991   NEG        POS\n",
      "128  ID-1184   POS        NEG\n",
      "\n",
      "For Fold 7 as dev \n",
      "POS: 85, NEG: 85\n",
      "Correct: 18, Total: 19, Accuracy: 94.736842\n",
      "          ID Class Pred_Class\n",
      "149  ID-0839   NEG        POS\n",
      "\n",
      "For Fold 8 as dev \n",
      "POS: 88, NEG: 82\n",
      "Correct: 19, Total: 19, Accuracy: 100.000000\n",
      "Empty DataFrame\n",
      "Columns: [ID, Class, Pred_Class]\n",
      "Index: []\n",
      "\n",
      "For Fold 9 as dev \n",
      "POS: 86, NEG: 85\n",
      "Correct: 18, Total: 18, Accuracy: 100.000000\n",
      "Empty DataFrame\n",
      "Columns: [ID, Class, Pred_Class]\n",
      "Index: []\n",
      "92.6315789474\n",
      "[89.473684210526315, 94.736842105263165, 94.736842105263165, 94.736842105263165, 89.473684210526315, 89.473684210526315, 78.94736842105263, 94.736842105263165, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.sentiment.util import mark_negation\n",
    "\n",
    "random.seed(1234)\n",
    "file_names = [\"hotelNegT-train.txt\", \"hotelPosT-train.txt\"]\n",
    "class_type_mappings = {\"hotelNegT-train.txt\": \"NEG\", \"hotelPosT-train.txt\": \"POS\"}\n",
    "class_list = [\"NEG\", \"POS\"]\n",
    "\n",
    "def get_reviews_raw(file_name, class_type):\n",
    "    with open(file_name) as review_file:\n",
    "        reviews = review_file.readlines()\n",
    "    reviews = map(lambda x : tuple((x.strip() + '\\t' + class_type).split('\\t')), reviews)\n",
    "    return reviews\n",
    "\n",
    "def get_all_reviews(file_names, class_type_mapping):\n",
    "    reviews_all = []\n",
    "    for file_name in file_names:\n",
    "        reviews_all.extend(get_reviews_raw(file_name, class_type_mapping[file_name]))\n",
    "        \n",
    "    random.shuffle(reviews_all)\n",
    "    return reviews_all\n",
    "\n",
    "def get_class(review):\n",
    "    return review[2]\n",
    "\n",
    "def get_class_probability(reviews_list, class_list):\n",
    "    result = pd.Series({x:0 for x in class_list})\n",
    "    for review in reviews_list:\n",
    "        result[get_class(review)] += 1.0\n",
    "    \n",
    "    total_reviews = len(reviews_list)\n",
    "    result = np.log(result/total_reviews)\n",
    "    return result\n",
    "\n",
    "def get_sent_tokenize(reviews):\n",
    "    return pd.DataFrame(map(lambda x : (x[0], tuple(sent_tokenize(x[1])), x[2]), reviews), columns = ['ID', 'Sentences', 'Class'])\n",
    "\n",
    "def word_tokenize_driver(sentence):\n",
    "    tokens = [ token.lower() for token in  mark_negation(word_tokenize(sentence), double_neg_flip= True) if token.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "def get_word_tokenize(review):\n",
    "    tokenizer = RegexpTokenizer(r'\\s+', gaps = True)\n",
    "    review['Word_Token'] = review['Sentences'].apply(lambda x : '\\n'.join(x))\n",
    "    review['Word_Token'] = review['Word_Token'].apply(lambda x : word_tokenize_driver(x))\n",
    "#     review_all['Word_Token'] = review_all['Word_Token'].apply(lambda x : tokenizer.tokenize(x))\n",
    "    \n",
    "def get_remove_stop_words(reviews):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    reviews['Word_Token_SW'] = reviews['Word_Token'].apply(lambda tokens :[token for token in tokens if token not in stop_words] )\n",
    "                \n",
    "def generate_bag_of_words(reviews):\n",
    "    reviews['bag_of_words'] = reviews['Word_Token_SW'].apply(lambda tokens : Counter(set(tokens)))\n",
    "    \n",
    "def get_bag_of_words(reviews):\n",
    "    result = Counter()\n",
    "    for bag_of_words in reviews.bag_of_words:\n",
    "        result.update(bag_of_words)\n",
    "    return result\n",
    "\n",
    "def get_vocab(reviews):\n",
    "    vocab = set()\n",
    "    for counter_bow in reviews['bag_of_words']:\n",
    "        vocab.update(counter_bow.keys())\n",
    "    return vocab\n",
    "\n",
    "def train_naive_bayes(train_reviews, class_list):\n",
    "    logprior = {}\n",
    "    loglikelihood = {}\n",
    "    vocab = get_vocab(train_reviews)\n",
    "    vocab_size = len(vocab)\n",
    "    for c in class_list:\n",
    "        n_doc = train_reviews.shape[0]\n",
    "        n_c = train_reviews[train_reviews.Class == c].shape[0]\n",
    "        logprior[c] = np.log(n_c*1.0/n_doc)\n",
    "        bag_of_words = get_bag_of_words(train_reviews[train_reviews.Class == c])\n",
    "        total_word_count_for_class = sum(bag_of_words.values())\n",
    "        \n",
    "        for word in vocab:\n",
    "            word_count_for_class = bag_of_words[word]\n",
    "            loglikelihood[(word, c)] = np.log((word_count_for_class + 1.0)/(total_word_count_for_class + vocab_size))\n",
    "    return logprior, loglikelihood, vocab\n",
    "\n",
    "def test_naive_bayes(test_review, logprior, loglikelihood, class_list, vocab):\n",
    "    pred_class_sum = {}\n",
    "    for c in class_list:\n",
    "        pred_class_sum[c] = logprior[c]\n",
    "        words = set(test_review['bag_of_words'].keys())\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                pred_class_sum[c] += loglikelihood[(word, c)]\n",
    "    \n",
    "#     for key, value in pred_class_sum.items():\n",
    "    return max(pred_class_sum, key = pred_class_sum.get)\n",
    "\n",
    "def k_fold_test(k = 10):\n",
    "    reviews_all = get_all_reviews(file_names, class_type_mappings)\n",
    "    reviews_all = get_sent_tokenize(reviews_all)\n",
    "    get_word_tokenize(reviews_all)\n",
    "    get_remove_stop_words(reviews_all)\n",
    "    generate_bag_of_words(reviews_all)\n",
    "    \n",
    "    count = reviews_all.shape[0]\n",
    "    print \"Total Count\", count\n",
    "    test_count = int (count * 1.0/ k) + 1\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for i in xrange(k):\n",
    "        mask = np.zeros(count, dtype=bool)\n",
    "        if i == k - 1:\n",
    "            mask[i * test_count:] = True\n",
    "        else:\n",
    "            mask[i * test_count: (i + 1) * test_count] = True\n",
    "        \n",
    "        print \"\\nFor Fold %s as dev \" % i\n",
    "    \n",
    "        train_reviews = reviews_all[~mask]\n",
    "        test_reviews = reviews_all[mask]\n",
    "        print \"POS: %d, NEG: %d\" % (np.sum(train_reviews.Class == 'POS'), np.sum(train_reviews.Class == 'NEG'))\n",
    "        logprior, loglikelihood, vocab = train_naive_bayes(train_reviews, class_list)\n",
    "        test_reviews['Pred_Class'] = test_reviews.apply(lambda x : test_naive_bayes(x, logprior, loglikelihood, class_list, vocab), axis = 1)\n",
    "        correct_pred = np.sum(test_reviews.Class == test_reviews.Pred_Class)\n",
    "        total_test_reviews = test_reviews.shape[0]\n",
    "        accuracy = correct_pred * 100.0/total_test_reviews\n",
    "        print \"Correct: %d, Total: %d, Accuracy: %f\" % (correct_pred, total_test_reviews, accuracy)\n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "        print test_reviews[test_reviews.Class != test_reviews.Pred_Class][['ID', 'Class', 'Pred_Class']]\n",
    "        \n",
    "    return accuracy_list, reviews_all\n",
    "            \n",
    "accuracy_list,df  = k_fold_test()\n",
    "\n",
    "print np.average(accuracy_list)\n",
    "\n",
    "print accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
